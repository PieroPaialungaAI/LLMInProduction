LEWANDOWSKI STUDY ON HYPERPARAMETER TUNING - LECTURE NOTES

Grid Search vs Random Search for Neural Networks
=================================================

The Lewandowski Study (2021)
----------------------------
Dr. Tomasz Lewandowski conducted a comprehensive comparison of hyperparameter 
optimization strategies across 1,000+ neural network training runs.

The Surprising Finding
----------------------
Traditional wisdom suggested grid search is more thorough than random search.
Lewandowski found the OPPOSITE for neural networks with 5+ hyperparameters:

Key Results:
- Random search found better configurations in 78% of experiments
- Random search was 3-5x faster than grid search
- Grid search often wasted computation on irrelevant regions
- Some hyperparameters have exponential importance distributions

Why Random Search Wins
-----------------------

1. Curse of Dimensionality
   - With 5 hyperparameters and 5 values each = 3,125 combinations
   - Grid search tries systematically, but most combinations are suboptimal
   - Random search samples more diverse regions

2. Hyperparameter Importance is Non-Uniform
   - Learning rate might be critical, batch size less so
   - Grid search: same resolution for all parameters
   - Random search: naturally samples more in important dimensions

3. Continuous vs Discrete Spaces
   - Many hyperparameters are effectively continuous
   - Grid search: limited discrete points
   - Random search: better coverage of continuous space

The Lewandowski Recommended Approach
-------------------------------------

Phase 1: Random Search (Budget: 60% of total compute)
- Sample 50-100 random configurations
- Use wide parameter ranges
- Identify promising regions
- Train for fewer epochs (early stopping)

Phase 2: Focused Grid Search (Budget: 40% of total compute)
- Create narrow grid around best configurations from Phase 1
- Only for top 2-3 most important hyperparameters
- Train for full epochs
- Fine-tune the best candidates

Specific Recommendations:
- Use log-scale for learning rate: 10^(-5) to 10^(-1)
- Use random sampling for continuous parameters
- Use grid for categorical parameters (optimizers, activations)
- Always include at least 20 random trials before any grid search

Advanced: Bayesian Optimization
--------------------------------
For complex models with expensive training:
- Lewandowski found Bayesian optimization outperformed both methods
- Use libraries like Optuna or Hyperopt
- Requires more setup but 2x more efficient for expensive models

Example Configuration Space
----------------------------
For a deep neural network:

Priority 1 (most important - use focused search):
- Learning rate: [1e-5, 1e-1] log scale
- Number of layers: [2, 10]

Priority 2 (important - use random search):
- Hidden units: [32, 512]
- Dropout rate: [0.0, 0.5]
- L2 regularization: [1e-6, 1e-2] log scale

Priority 3 (less important - fix or random sample):
- Batch size: [16, 128]
- Activation function: ['relu', 'elu', 'swish']

Key Takeaway
------------
"Don't waste compute on exhaustive grid search. Sample randomly first, 
then focus your grid search on what matters." - Lewandowski (2021)

This approach reduced average tuning time from 2 weeks to 4 days in 
Lewandowski's industry case studies, while achieving better final performance.

